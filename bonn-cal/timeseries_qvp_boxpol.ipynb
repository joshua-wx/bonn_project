{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wradlib as wrl\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "try:\n",
    "    get_ipython().magic(\"matplotlib inline\")\n",
    "except:\n",
    "    pl.ion()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "import dateutil.parser as dparser\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries/QVP ODIM_H5 using XARRAY\n",
    "\n",
    "This shows loading of a series of sweeps of BoXPol Radar using `wradlib.io.xarray.OdimH5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wradlib.io.xarray import OdimH5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check coordinates\n",
    "\n",
    "The CfRadial2.0 standard has one `time`/`azimuth` dimension/coordinate already defined. We need to take some precautions to check this for problems and prevent further code from breaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_azimuth(ds):\n",
    "    \"\"\"reindex azimuth - missing rays, double rays\n",
    "    \"\"\"\n",
    "    dim = ds.azimuth.dims[0]\n",
    "    res = ds.azimuth.diff(dim).median().round(decimals=1)\n",
    "    azr = np.arange(res/2., 360, res)\n",
    "    ds = ds.sortby('azimuth').reindex(azimuth=azr, method='nearest', tolerance=res/4.)\n",
    "    return ds\n",
    "\n",
    "def check_elevation(ds):\n",
    "    \"\"\"assign elevation - might just use elevation from root-ds or median\n",
    "    \"\"\"\n",
    "    elr = np.ones(ds.azimuth.shape) * np.round(np.nanmedian(ds.elevation.values), decimals=1)\n",
    "    ds = ds.assign_coords(elevation=(['azimuth'], elr))\n",
    "    return ds\n",
    "\n",
    "def check_time(ds):\n",
    "    # rename time coordinate/variable and add new time\n",
    "    ds = ds.rename({'time': 'rtime'})#.expand_dims('time')\n",
    "    ds = ds.assign({'start_time': (['time'], [ds['rtime'].values[0]])})\n",
    "    # assign new time coordinate\n",
    "    ds = ds.assign({'time': (['time'], ds['start_time'])})\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Georeference Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def georeference_dataset(ds, is_ppi):\n",
    "    \"\"\"Georeference Dataset.\n",
    "\n",
    "    This function adds georeference data to xarray dataset `ds`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xarray dataset\n",
    "    is_ppi : bool\n",
    "        PPI/RHI flag\n",
    "    \"\"\"\n",
    "    # adding xyz aeqd-coordinates\n",
    "    site = (ds.coords['longitude'].values, ds.coords['latitude'].values,\n",
    "            ds.coords['altitude'].values)\n",
    "    dim0 = ds['azimuth'].dims[0]\n",
    "    xyz, aeqd = wrl.georef.spherical_to_xyz(ds['range'],\n",
    "                                            ds['azimuth'],\n",
    "                                            ds['elevation'],\n",
    "                                            site,\n",
    "                                            squeeze=True)\n",
    "    gr = np.sqrt(xyz[..., 0] ** 2 + xyz[..., 1] ** 2)\n",
    "    ds.coords['x'] = ([dim0, 'range'], xyz[..., 0])\n",
    "    ds.coords['y'] = ([dim0, 'range'], xyz[..., 1])\n",
    "    ds.coords['z'] = ([dim0, 'range'], xyz[..., 2])\n",
    "    ds.coords['gr'] = ([dim0, 'range'], gr)\n",
    "\n",
    "    # adding rays, bins coordinates\n",
    "    if is_ppi:\n",
    "        bins, rays = np.meshgrid(ds['range'],\n",
    "                                 ds['azimuth'],\n",
    "                                 indexing='xy')\n",
    "    else:\n",
    "        bins, rays = np.meshgrid(ds['range'],\n",
    "                                 ds['elevation'],\n",
    "                                 indexing='xy')\n",
    "    ds.coords['rays'] = ([dim0, 'range'], rays)\n",
    "    ds.coords['bins'] = ([dim0, 'range'], bins)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perdelta(start, end, delta):\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        yield curr\n",
    "        curr += delta\n",
    "        \n",
    "def get_data_path(inpath):\n",
    "    \"\"\" Get data path (automount) \n",
    "    \"\"\"\n",
    "    return os.path.join(inpath, '{year}/{year}-{month:02d}/'\n",
    "                                '{year}-{month:02d}-{day:02d}/{scan}')\n",
    "\n",
    "def get_file_name_new():\n",
    "    return ('{scan}_12345_{year}{month:02d}{day:02d}{hour:02d}{mintens}'\n",
    "            '[{minones0}-{minones1}]*')\n",
    "\n",
    "def get_file_name_old():\n",
    "    return ('{year}-{month:02d}-{day:02d}--{hour:02d}:{mintens}'\n",
    "            '[{minones0}-{minones1}]*')\n",
    "\n",
    "def import_dates(date_string):\n",
    "    return dparser.parse(date_string)\n",
    "\n",
    "def get_time_offset(val):\n",
    "    t0 = dt.datetime.utcfromtimestamp(val.astype(int) * 1e-9)\n",
    "    t1 = dt.datetime(t0.year, t0.month, t0.day, t0.hour, t0.minute)\n",
    "    return t0-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timeseries(flist, **kwargs):\n",
    "    disable = len(flist) == 1\n",
    "    root = []\n",
    "    sweep = []\n",
    "    first = True\n",
    "    i = 0\n",
    "    for fname in tqdm(flist, 'scans', ascii=True, disable=disable):\n",
    "        # Handle missing scans\n",
    "        try:\n",
    "            fname = fname[0]\n",
    "        except IndexError:\n",
    "            continue\n",
    "        ds0 = OdimH5(fname, flavour='GAMIC', **kwargs)\n",
    "        root.append(ds0['root'])\n",
    "        sweep.append(ds0['sweep_1'].pipe(check_azimuth).pipe(check_elevation).pipe(check_time))\n",
    "\n",
    "    ds_root = xr.concat(root, dim='time', data_vars='different')\n",
    "    ds_sweep = xr.concat(sweep, dim='time', data_vars='different', coords='different')\n",
    "    return {'root': ds_root, 'sweep_1': ds_sweep}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load timeseries of sweeps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to claim all files which corresponds to the specific sweep and time range. So we take a wanted `start_time`, `stop_time` and `scan` and retrieve all fitting ppi sweeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recent boxpol event\n",
    "start_time = dt.datetime(2019, 5, 21, 14)\n",
    "stop_time = dt.datetime(2019, 5, 21, 16)\n",
    "\n",
    "inpath = '/automount/radar/scans'\n",
    "#inpath = '/automount/radar-archiv/scans'\n",
    "\n",
    "scan = 'n_ppi_180deg'\n",
    "startmin = 0\n",
    "stopmin = 3\n",
    "\n",
    "drange = [result for result in\n",
    "          perdelta(start_time, stop_time, dt.timedelta(minutes=5))]\n",
    "\n",
    "path = get_data_path(inpath)\n",
    "path = os.path.join(path, get_file_name_new())\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create file list\n",
    "\n",
    "To retrieve the sweeps for every timestep `glob` module is used with the prepared path variable. Finally, one timestep is removed from the list to simulate a missing sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = [glob.glob(path.format(year=t.year, month=t.month, day=t.day, \n",
    "                               scan=scan,  \n",
    "                               hour=t.hour, mintens=int(t.minute / 10),\n",
    "                               minones0=t.minute % 10 + startmin,\n",
    "                               minones1=t.minute % 10 + stopmin)) for t in drange]\n",
    "print(len(flist))\n",
    "flist[10] = []\n",
    "flist[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load timeseries\n",
    "\n",
    "Here `create_timeseries` is used with the given keyword arguments `dim0='azimuth'` and `georef=False`. This will use `azimuth` as first dimension (instead of `time`) and will not add georeferenced coordinates to everey sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = create_timeseries(flist, dim0='azimuth', georef=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts['root']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts['sweep_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reindex time - fix missing timesteps\n",
    "\n",
    "For a timeseries of sweeps not all measurements might be available. So we have to deal with missing sweeps at any position in the series. The solution is to reindex along the `time`-dimension using the precomputed `drange` array (5 minute resolution).\n",
    "\n",
    "First we transform the `drange` data type to `np.datetime64` for use with xarray. Then we reindex along the time dimension using nearest neighbour with a tolerance of 150 s (2.5 minutes).\n",
    "\n",
    "Note that the resulting `time`-coordinate is in a fixed 5 minute interval (00:00, 00:05, ..., 00:55, 01:00, 01:05, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntime = np.array([np.datetime64(dr) for dr in drange])\n",
    "ts['sweep_1'] = ts['sweep_1'].reindex(time=ntime, method='nearest', tolerance=150e+9)\n",
    "ts['sweep_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Georeference timeseries\n",
    "\n",
    "Georeferenced AEQD coordinates xyz, gr and rays, bins can be attached using `georeference_dataset` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts['sweep_1'] = ts['sweep_1'].pipe(georeference_dataset, is_ppi=True)\n",
    "ts['sweep_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign height-coord from z-coord\n",
    "\n",
    "For QVP a height-coordinate is needed. It is derived from the dataset's `z`-coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts['sweep_1'] = ts['sweep_1'].assign_coords(height=ts['sweep_1'].z.mean('azimuth'))\n",
    "ts['sweep_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the data using `hvplot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbz_plot = ts['sweep_1'].hvplot.quadmesh(groupby='time', \n",
    "                                          x='x', y='y', \n",
    "                                          z='DBZH', \n",
    "                                          rasterize=True, \n",
    "                                          clim=(0,50), cmap='Spectral',\n",
    "                                          width=600, height=500)\n",
    "dbz_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Simple QVP\n",
    "\n",
    "The QVP is created using a median along the `azimuth` dimension. This will collapse the `azimuth` dimension and we obtain an output dataset of `time`x`range`. Note that the `azimuth`-dimension is gets removed and all variables which cannot be collapsed correctly (xyz-coordinates etc.) will be removed.\n",
    "\n",
    "Generally all available numpy statistic functions can be used here (eg. 'mean', 'std', etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvp = ts['sweep_1'].median('azimuth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple QVP Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = pl.subplots(ncols=2, nrows=2, figsize=(16,16))\n",
    "print(axes)\n",
    "qvp.DBZH.where(qvp.DBZH>0).plot(x='time', y='height', ax=axes[0,0], vmin=0, vmax=50)\n",
    "qvp.RHOHV.where(qvp.DBZH>0).plot(x='time', y='height', ax=axes[0,1], vmin=0, vmax=1)\n",
    "qvp.ZDR.where(qvp.DBZH>0).plot(x='time', y='height', ax=axes[1,0], vmin=-2, vmax=4)\n",
    "qvp.PHIDP.where(qvp.DBZH>0).plot(x='time', y='height', ax=axes[1,1], vmin=75, vmax=95)\n",
    "pl.tight_layout()\n",
    "\n",
    "[ax.set_ylim(0, 7000) for ax in axes.flat]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
