{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nImplementation of the Improved LBDT technique\\nYuan et al. 2018 An Algorthim for Autoamted Identification of Gust Fronts from Doppler Radar Data. J. Met. Res.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implementation of the Improved LBDT technique\n",
    "Yuan et al. 2018 An Algorthim for Autoamted Identification of Gust Fronts from Doppler Radar Data. J. Met. Res.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime as dt\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import ndimage\n",
    "from skimage import morphology, draw\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import helper_functions as util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ridges_new(image_index):\n",
    "    \"\"\"\n",
    "    Equation (2) from Yuan et al. 2018\n",
    "    \"\"\"\n",
    "    #extract refl data\n",
    "    refl_img_full = refl_data[image_index, :,:]\n",
    "    #crop to valid data\n",
    "    refl_img_crop = refl_img_full[:, x_start:] \n",
    "    \n",
    "    #smooth image\n",
    "    refl_img_prep = ndimage.filters.gaussian_filter(refl_img_crop, 0.5)\n",
    "\n",
    "    #valid reflectivity mask\n",
    "    valid_refl_mask = np.logical_and(refl_img_prep>=min_refl, refl_img_prep<=max_refl)\n",
    "    #convolution filers filter\n",
    "    g2_size    = 4*n_parm + 3\n",
    "    conv_filt = ndimage.uniform_filter(refl_img_prep, size=g2_size, mode='constant', cval=min_value)\n",
    "    #foreground mask\n",
    "    ridges_mask  = np.logical_and(refl_img_prep > conv_filt, valid_refl_mask)\n",
    "    \n",
    "    \n",
    "    return ridges_mask, refl_img_prep, refl_img_crop\n",
    "\n",
    "def find_ridges_old(image_index):\n",
    "    \n",
    "    #extract refl data\n",
    "    refl_img_full = refl_data[image_index, :,:]\n",
    "\n",
    "    #crop to valid data\n",
    "    refl_img_crop = refl_img_full[:, x_start:] \n",
    "\n",
    "    #discreise reflectivity\n",
    "    refl_img_int = util.refl_to_int(refl_img_crop)\n",
    "\n",
    "    #valid reflectivity mask\n",
    "    valid_refl_mask = np.logical_and(refl_img_int>=min_refl, refl_img_int<=max_refl)\n",
    "\n",
    "    #g1 and g2 convolution filers filter\n",
    "    g1_size    = 2*n_parm + 1\n",
    "    g2_size    = 4*n_parm + 3\n",
    "    conv_g1    = ndimage.uniform_filter(refl_img_int, size=g1_size, mode='constant', cval=min_value)\n",
    "    conv_g2    = ndimage.uniform_filter(refl_img_int, size=g2_size, mode='constant', cval=min_value)\n",
    "\n",
    "    #foreground mask\n",
    "    inital_mask = np.logical_and(refl_img_int >= conv_g1, refl_img_int > conv_g2)\n",
    "    ridges_mask = np.logical_and(inital_mask, valid_refl_mask)\n",
    "    \n",
    "    return ridges_mask, refl_img_int, refl_img_crop\n",
    "\n",
    "\n",
    "def ridges_to_skeleton(ridges_mask):\n",
    "\n",
    "    #Smooth Ridge Regions\n",
    "    dilation_filter = np.array([[0,1,0],[1,1,1],[0,1,0]], np.uint8) #use circular filter shape\n",
    "    ridges_mask = morphology.binary_dilation(ridges_mask, dilation_filter)\n",
    "    \n",
    "    #remove ridge regions by maximum length\n",
    "    label_ridges_image, n_features = morphology.label(ridges_mask, neighbors=8, background=False, return_num=True, connectivity=1)\n",
    "    for label_idx in np.arange(1,n_features):\n",
    "        #calculate bounding box length\n",
    "        [i_coord, j_coord] = np.where(label_ridges_image==label_idx)\n",
    "        bb_length = np.sqrt((np.max(i_coord) - np.min(i_coord))**2 + (np.max(j_coord) - np.min(j_coord))**2)\n",
    "        if bb_length < min_length:\n",
    "            ridges_mask[label_ridges_image==label_idx] = False\n",
    "    \n",
    "    #################################\n",
    "    # STEP 3: Generate Skeleton\n",
    "    #################################     \n",
    "    skeleton = morphology.thin(ridges_mask)\n",
    "    \n",
    "    return skeleton, ridges_mask\n",
    "\n",
    "def remove_intersections(skeleton):\n",
    "\n",
    "    \"\"\"\n",
    "    Remove intersections from skeleton using LBP technique (section 2.4.1)\n",
    "    \"\"\"\n",
    "    \n",
    "    #pass 1: remove most intersections\n",
    "    n3_conv_pass1  = ndimage.generic_filter(skeleton.astype(int), util.lbp_filter, footprint=n3_window, mode='constant', cval=0)\n",
    "    n5_conv_pass1  = ndimage.generic_filter(skeleton.astype(int), util.lbp_filter, footprint=n5_window, mode='constant', cval=0)\n",
    "    #find\n",
    "    xsec_point_mask1 = np.logical_and(n3_conv_pass1>=6, n5_conv_pass1>=6) #if n3 or n5 contain 6 changes, then it's an intersection\n",
    "    xsec_point_mask1[skeleton==False] = False\n",
    "\n",
    "    #break skeleton at intersection points\n",
    "    skeleton[xsec_point_mask1] = False\n",
    "\n",
    "    #pass 2: remove diagonal connecting points left over from T junctions (also removes any burrs)\n",
    "    n3_conv_pass2 = ndimage.generic_filter(skeleton.astype(int), util.lbp_filter, footprint=n3_window, mode='constant', cval=0)\n",
    "    xsec_point_mask2 = np.logical_and(n3_conv_pass2>=6, skeleton) #if n3 or n5 contain 6 changes, then it's an intersection\n",
    "    \n",
    "    #skeleton[ndimage.morphology.binary_dilation(xsec_point_mask, dilation_filter)] = False\n",
    "    skeleton[xsec_point_mask2] = False\n",
    "    #combine xsec masks\n",
    "    xsec_point_mask = np.logical_or(xsec_point_mask1, xsec_point_mask2)\n",
    "    \n",
    "    return skeleton, xsec_point_mask\n",
    "\n",
    "\n",
    "def remove_turning_points(skeleton):\n",
    "    \n",
    "    \"\"\"\n",
    "    remove turning points by checking rate of turning across line segments (section 2.4.1)\n",
    "    \"\"\"    \n",
    "    turn_point_mask = np.zeros_like(skeleton, dtype=bool)\n",
    "    #run labelling\n",
    "    label_image, n_features = morphology.label(skeleton, neighbors=8, background=False, return_num=True, connectivity=1)\n",
    "    #for each label\n",
    "    for label_idx in np.arange(1,n_features):\n",
    "        #remove short segments\n",
    "        label_count = np.sum([label_image==label_idx])\n",
    "        #skip features smaller than the filter\n",
    "        if label_count < (turnpt_vlen*2 + 1):\n",
    "            #skeleton[label_image == label_idx] = False\n",
    "            continue\n",
    "            \n",
    "        # extract line points\n",
    "        i_pts, j_pts = np.where(label_image==label_idx)\n",
    "        points = np.c_[i_pts, j_pts]\n",
    "        # compute order of shortest line along points\n",
    "        opt_order = util.order_points(points)\n",
    "        points = points[opt_order]\n",
    "        #compute turning angles\n",
    "        try:\n",
    "            #compute turning angles\n",
    "            out_deg = util.vector_pair_angle(points[:,1], points[:,0], turnpt_vlen)\n",
    "            #apply masking\n",
    "            turning_pt_idx = np.where(out_deg < turnpt_angle_threshold)[0] + turnpt_vlen\n",
    "            turn_point_mask[points[turning_pt_idx,0],points[turning_pt_idx,1]] = True\n",
    "        except Exception as e:\n",
    "            print('turning point calc exception')\n",
    "            pass\n",
    "    \n",
    "    #apply turning point_mask\n",
    "    skeleton[turn_point_mask] = False\n",
    "    \n",
    "    return skeleton, turn_point_mask\n",
    "\n",
    "def find_end_points_and_theta(skeleton):\n",
    "    \n",
    "    #find theta\n",
    "    end_point_theta = np.zeros_like(skeleton, dtype=float)\n",
    "    end_point_theta.fill(np.nan)\n",
    "    #run labelling\n",
    "    label_image, n_features = morphology.label(skeleton, neighbors=8, background=False, return_num=True, connectivity=1)\n",
    "    #for each label\n",
    "    for label_idx in np.arange(1,n_features):\n",
    "        #remove short segments\n",
    "        label_count = np.sum([label_image==label_idx])\n",
    "        #skip features smaller than the filter\n",
    "        if label_count < connect_calc_minpts + 1:\n",
    "            skeleton[label_image == label_idx] = False\n",
    "            continue\n",
    "        #check for length and adjust maxpts to mid point\n",
    "        if int(label_count/2) > connect_calc_minpts:\n",
    "            connect_calc_pts = int(label_count/2)\n",
    "        else:\n",
    "            connect_calc_pts = connect_calc_minpts\n",
    "        # extract line points\n",
    "        i_pts, j_pts = np.where(label_image==label_idx)\n",
    "        points = np.c_[i_pts, j_pts]\n",
    "        # compute order of shortest line along points\n",
    "        opt_order = util.order_points(points)\n",
    "        points = points[opt_order]   \n",
    "        #allocate end point angles using end point and 3rd point from the end\n",
    "        end_point_theta[points[0,0] , points[0,1]]  = util.line_angle(points, connect_calc_pts)\n",
    "        end_point_theta[points[-1,0], points[-1,1]] = util.line_angle(np.flip(points, 0), connect_calc_pts) #flip so end point starts array\n",
    "    \n",
    "    #find end points using conv filter from intersections\n",
    "    n3_conv        = ndimage.generic_filter(skeleton.astype(int), util.lbp_filter, footprint=n3_window, mode='constant', cval=0)\n",
    "    end_point_mask  = n3_conv==2\n",
    "    end_point_mask[skeleton==False] = False\n",
    "    \n",
    "    return skeleton, end_point_mask, end_point_theta\n",
    "\n",
    "def connect_end_points(skeleton, end_point_mask, end_point_theta, refl_img_prep):\n",
    "    \"\"\"\n",
    "    connect end points using a series of tests for end points and line segment properties (section 2.4.2)\n",
    "    \"\"\"\n",
    "    \n",
    "    #create end point mask and coord list\n",
    "    connect_point_mask = np.zeros_like(skeleton, dtype=bool)\n",
    "    i_pts, j_pts  = np.where(end_point_mask)\n",
    "    end_points    = np.c_[i_pts, j_pts]\n",
    "\n",
    "    #create dilated skeleton for checking for creation of new intersections and overlaps with existing skeleton\n",
    "    dilation_filter  = np.array([[1,1,1],[1,1,1],[1,1,1]], np.uint8) #use circular filter shape\n",
    "    dilated_skeleton = morphology.binary_dilation(skeleton.copy(), dilation_filter)   \n",
    "\n",
    "    #init connection point list\n",
    "    connpt_coord_list  = []\n",
    "    connpt_weight_list = []\n",
    "    \n",
    "    #for each point\n",
    "    for origin_point in end_points:\n",
    "\n",
    "        #calc distance\n",
    "        dist_array = np.sqrt((origin_point[0]-end_points[:,0])**2 + (origin_point[1]-end_points[:,1])**2)*grid_size_km\n",
    "        #find possible matches\n",
    "        match_idx_list = np.where(np.logical_and(dist_array>0, dist_array<=connect_dist_max))[0]\n",
    "        dist_array_set = dist_array[match_idx_list]\n",
    "        #sort by distance (so closest is processed first)\n",
    "        sort_idx       = np.argsort(dist_array[match_idx_list])\n",
    "        match_idx_list = match_idx_list[sort_idx]\n",
    "        dist_array     = dist_array_set[sort_idx]\n",
    "        #join new matches\n",
    "        for i, match_idx in enumerate(match_idx_list):\n",
    "            #extract i,j coords of test end point for connection\n",
    "            test_point = end_points[match_idx]\n",
    "            \n",
    "            #extract theta of origin and test end point for connection\n",
    "            a_theta  = end_point_theta[origin_point[0], origin_point[1]] #origin\n",
    "            b_theta  = end_point_theta[test_point[0], test_point[1]] #test\n",
    "            #calculate vectors between origin and test\n",
    "            ab_theta = util.points_angle(origin_point, test_point)\n",
    "            ba_theta = util.points_angle(test_point, origin_point)\n",
    "            #cosine similarity tests\n",
    "            test1 = util.cosine_test(ba_theta, a_theta)\n",
    "            test2 = util.cosine_test(ab_theta, b_theta)\n",
    "            test3 = util.cosine_test(b_theta, a_theta)\n",
    "            #run test\n",
    "            test_threshold = math.cos(math.radians(cosine_test_val)) # -0.7 test threshold\n",
    "            if test1 > test_threshold or test2 > test_threshold or test3 > test_threshold:\n",
    "                continue\n",
    "        \n",
    "            #generate line between points\n",
    "            rr, cc = draw.line(origin_point[0], origin_point[1], test_point[0], test_point[1])\n",
    "\n",
    "            #check for crossing existing skeleton or creating new intersections (using a dilated skeleton)\n",
    "            line_skeleton = dilated_skeleton[rr, cc]\n",
    "            if np.sum(line_skeleton)>4: #remember, we are using a dilated skeleton, so a correct connection will have an overlap of 4\n",
    "                continue\n",
    "\n",
    "            #check for crossing new connections\n",
    "            line_connect = connect_point_mask[rr, cc]\n",
    "            if np.any(line_connect):\n",
    "                continue\n",
    "                \n",
    "            #check for reflectivity limits\n",
    "            line_refl     = refl_img_prep[rr, cc]\n",
    "            if np.any(line_refl<min_line_refl) or np.any(line_refl>max_line_refl):\n",
    "                continue\n",
    "                \n",
    "            #print('connection added')\n",
    "            #connect_point_mask[rr, cc] = True\n",
    "            connpt_coord_list.append(np.array([rr,cc]).T)\n",
    "            connpt_weight_list.append(dist_array[i])\n",
    "            break\n",
    "            \n",
    "    #################    \n",
    "    #rank overlapping conn_points by min distance\n",
    "    process_flag = np.zeros_like(connpt_coord_list, dtype=bool)\n",
    "    for i, conn_pt in enumerate(connpt_coord_list):\n",
    "        #check if already processed\n",
    "        if process_flag[i]:\n",
    "            continue\n",
    "        #mark as processed\n",
    "        process_flag[i] = True\n",
    "        #find overlapping arrays\n",
    "        overlap_idx  = [i] \n",
    "        overlap_dist = [connpt_weight_list[i]]\n",
    "        for j, test_pt in enumerate(connpt_coord_list):\n",
    "            if process_flag[j]:\n",
    "                continue\n",
    "            elif util.coor_intersect_test(conn_pt,test_pt):\n",
    "                overlap_idx.append(j)\n",
    "                overlap_dist.append(connpt_weight_list[j])\n",
    "        if len(overlap_idx) == 1: #no overlaps\n",
    "            connect_point_mask[conn_pt[:,0], conn_pt[:,1]] = True\n",
    "        else:\n",
    "            #find index of min distance connection\n",
    "            min_idx = np.argmin(overlap_dist)\n",
    "            conn_idx = overlap_idx[min_idx]\n",
    "            #apply to connect mask\n",
    "            connect_point_mask[connpt_coord_list[conn_idx][:,0], connpt_coord_list[conn_idx][:,1]] = True\n",
    "            #flag all points as processed\n",
    "            process_flag[overlap_idx] = True\n",
    "                \n",
    "        \n",
    "    #end_point_theta[connect_point_mask] = np.nan\n",
    "    skeleton[connect_point_mask] = True\n",
    "    \n",
    "    return skeleton, connect_point_mask\n",
    "\n",
    "def remove_short_lines(skeleton):\n",
    "    \"\"\"\n",
    "    Remove regions smaller than min_length\n",
    "    \"\"\"\n",
    "    #run labelling\n",
    "    label_image, n_features = morphology.label(skeleton, neighbors=8, background=False, return_num=True, connectivity=1)\n",
    "    #for each label\n",
    "    for label_idx in np.arange(1,n_features):\n",
    "        #remove short segments\n",
    "        label_count = np.sum([label_image==label_idx])\n",
    "        #skip features smaller than the filter\n",
    "        if label_count < min_length:\n",
    "            skeleton[label_image == label_idx] = False\n",
    "            continue\n",
    "            \n",
    "    return skeleton\n",
    "\n",
    "def filter_edges_radialnoise(skeleton, refl_img_prep):\n",
    "  \n",
    "    \"\"\"\n",
    "    remove line segments that are part of reflectivity edges and remove radial noise (section 2.5)_\n",
    "    \"\"\"\n",
    "    #label image and remove by pixel count and 95th percentile\n",
    "    label_image, n_features = morphology.label(skeleton, neighbors=8, background=False, return_num=True, connectivity=1)\n",
    "    for label_idx in np.arange(1,n_features):\n",
    "\n",
    "        #calculate PCA for line\n",
    "        i_idx, j_idx = np.where(label_image==label_idx)\n",
    "        line_points  = np.column_stack((i_idx, j_idx))\n",
    "        pca = PCA(n_components=2).fit(line_points)\n",
    "        feature_vectors = pca.components_.T\n",
    "        nvec            = feature_vectors[1] #use second PCA component for the unit normal vector\n",
    "            \n",
    "        #run filter on line segment\n",
    "        a0, b0 = util.edge_filter_wrapper(refl_img_prep, nvec, line_points)\n",
    "        \n",
    "        #contine if a true ridge\n",
    "        edge_filter_threshold = 0\n",
    "        if a0 >= edge_filter_threshold and b0 >= edge_filter_threshold:\n",
    "            continue\n",
    "        \n",
    "        #if a0 < edge_filter_threshold and b0 < edge_filter_threshold:\n",
    "        #    continue\n",
    "        \n",
    "        #remove line if it fails this test\n",
    "        skeleton[label_image == label_idx] = False\n",
    "    \n",
    "    return skeleton\n",
    "\n",
    "def skeleton_to_thinlines(skeleton, ridges_mask):\n",
    "    \"\"\"\n",
    "    preserve thin lines\n",
    "    \"\"\"\n",
    "    thinlines_mask = np.zeros_like(ridges_mask, dtype=bool)\n",
    "    #run labelling\n",
    "    label_image, n_features = morphology.label(ridges_mask, neighbors=8, background=False, return_num=True, connectivity=1)\n",
    "    #for each label\n",
    "    for label_idx in np.arange(1,n_features):\n",
    "        #check if ridge feature contains a skeleton\n",
    "        if np.any(skeleton[label_image == label_idx]):\n",
    "            thinlines_mask[label_image == label_idx] = True\n",
    "            \n",
    "    return thinlines_mask    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot_simple(refl_img_prep, refl_img_crop, thinlines_mask, initial_skeleton, \n",
    "                  xsec_point_mask, turn_point_mask, end_point_mask, \n",
    "                  end_point_theta, connect_point_mask, final_skeleton, image_index):\n",
    "    \"\"\"\n",
    "    plotting routine for boundary detection\n",
    "    \"\"\"\n",
    "    #setup figure\n",
    "    figsize = (20, 10)\n",
    "    plt.clf()\n",
    "    fig = plt.figure(facecolor='white', figsize=figsize)\n",
    "    \n",
    "    #subplot 1\n",
    "    ax0 = plt.subplot(1,2,1)\n",
    "    #add image\n",
    "    im0 = ax0.imshow(refl_img_prep.astype('float'))\n",
    "    #add initial skeleton\n",
    "    [line_i, line_j] = np.where(initial_skeleton)\n",
    "    ax0.plot(line_j, line_i, 'w.', markersize=ridge_markersz)\n",
    "    #overlay xsection\n",
    "    [line_i, line_j] = np.where(xsec_point_mask)\n",
    "    ax0.plot(line_j, line_i, 'k.', markersize=feat_markersz)    \n",
    "    #overlay turning points\n",
    "    [line_i, line_j] = np.where(turn_point_mask)\n",
    "    ax0.plot(line_j, line_i, 'r*', markersize=feat_markersz)   \n",
    "    #overlay end points\n",
    "    [line_i, line_j] = np.where(end_point_mask)\n",
    "    ax0.plot(line_j, line_i, 'wo', markersize=feat_markersz)  \n",
    "    #overlay end point vectors\n",
    "    end_point_mask = ~(np.isnan(end_point_theta))\n",
    "    [end_i, end_j] = np.where(end_point_mask)\n",
    "    for i,_ in enumerate(end_i):\n",
    "        angle = math.radians(end_point_theta[end_i[i], end_j[i]])\n",
    "        angle_int = int(end_point_theta[end_i[i], end_j[i]])\n",
    "        plt.arrow(end_j[i], end_i[i], 4.5*math.cos(angle), 4.5*math.sin(angle))\n",
    "        #plt.text(end_j[i], end_i[i], str(angle_int), color='w',size=15)\n",
    "    ax0.plot(end_j, end_i, 'wo', markersize=feat_markersz)\n",
    "    #overlay connection points\n",
    "    [line_i, line_j] = np.where(connect_point_mask)\n",
    "    ax0.plot(line_j, line_i, 'yo', markersize=feat_markersz_connect)   \n",
    "    #ax0.set_title('Reflectivity')\n",
    "    #fig.colorbar(im0, ax=ax0)\n",
    "    #zoom if required\n",
    "    if zoom:\n",
    "        ax0.set_ylim(zoom_y)\n",
    "        ax0.set_xlim(zoom_x)\n",
    "        \n",
    "    #subplot 2\n",
    "    ax1 = plt.subplot(1,2,2)\n",
    "    #plot reflectivity\n",
    "    im1 = ax1.imshow(refl_img_crop.astype('float'))\n",
    "    #overlay final skeleton\n",
    "    [line_i, line_j] = np.where(final_skeleton)\n",
    "    ax1.plot(line_j, line_i, 'w.', markersize=ridge_markersz)   \n",
    "    if zoom:\n",
    "        ax1.set_ylim(zoom_y)\n",
    "        ax1.set_xlim(zoom_x)\n",
    "        \n",
    "    #save\n",
    "    if save_flag:\n",
    "        image_ffn = output_path_simple + '/' + str(image_index).zfill(3) + '.png'\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(image_ffn, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot_full(refl_img_prep, refl_img_crop,\n",
    "                            initial_skeleton,\n",
    "                            xsec_skeleton, xsec_point_mask,\n",
    "                            turn_skeleton, turn_point_mask, \n",
    "                            end_point_skeleton, end_point_mask, end_point_theta,\n",
    "                            conn_skeleton, connect_point_mask,\n",
    "                            clean_skeleton,\n",
    "                            filter_skeleton,\n",
    "                            image_index):\n",
    "    \"\"\"\n",
    "    plotting routine for boundary detection\n",
    "    \"\"\"\n",
    "    #setup figure\n",
    "    figsize = (20, 40)\n",
    "    plt.clf()\n",
    "    fig = plt.figure(facecolor='white', figsize=figsize)\n",
    "    \n",
    "    ##subplot 1 - inital\n",
    "    ax1 = plt.subplot(3,2,1)\n",
    "    ax1.set_title('Inital Skeleton')\n",
    "    im1 = ax1.imshow(refl_img_prep.astype('float'))\n",
    "    #add skeleton\n",
    "    [line_i, line_j] = np.where(initial_skeleton)\n",
    "    ax1.plot(line_j, line_i, 'w.', markersize=ridge_markersz)\n",
    "    \n",
    "    ##subplot 2- xsec\n",
    "    ax2= plt.subplot(3,2,2)\n",
    "    ax2.set_title('Xsec Points')\n",
    "    im2 = ax2.imshow(refl_img_prep.astype('float'))\n",
    "    #add skeleton\n",
    "    [line_i, line_j] = np.where(xsec_skeleton)\n",
    "    ax2.plot(line_j, line_i, 'w.', markersize=ridge_markersz)\n",
    "    #overlay xsection\n",
    "    [line_i, line_j] = np.where(xsec_point_mask)\n",
    "    ax2.plot(line_j, line_i, 'k.', markersize=feat_markersz)\n",
    "        \n",
    "    ##subplot 3 - turning points\n",
    "    ax3 = plt.subplot(3,2,3)\n",
    "    ax3.set_title('Turning Points')\n",
    "    im3 = ax3.imshow(refl_img_prep.astype('float'))\n",
    "    #add skeleton\n",
    "    [line_i, line_j] = np.where(turn_skeleton)\n",
    "    ax3.plot(line_j, line_i, 'w.', markersize=ridge_markersz)\n",
    "    #overlay xsection\n",
    "    [line_i, line_j] = np.where(turn_point_mask)\n",
    "    ax3.plot(line_j, line_i, 'k.', markersize=feat_markersz)\n",
    "        \n",
    "    ##subplot 4 - end points\n",
    "    ax4 = plt.subplot(3,2,4)\n",
    "    ax4.set_title('End Points')\n",
    "    im4 = ax4.imshow(refl_img_prep.astype('float'))\n",
    "    #add skeleton\n",
    "    [line_i, line_j] = np.where(end_point_skeleton)\n",
    "    ax4.plot(line_j, line_i, 'w.', markersize=ridge_markersz)\n",
    "    #overlay end point vectors\n",
    "    end_point_mask = ~(np.isnan(end_point_theta))\n",
    "    [end_i, end_j] = np.where(end_point_mask)\n",
    "    for i,_ in enumerate(end_i):\n",
    "        angle = math.radians(end_point_theta[end_i[i], end_j[i]])\n",
    "        angle_int = int(end_point_theta[end_i[i], end_j[i]])\n",
    "        ax4.arrow(end_j[i], end_i[i], 4.5*math.cos(angle), 4.5*math.sin(angle))\n",
    "        #plt.text(end_j[i], end_i[i], str(angle_int), color='w',size=15)\n",
    "    ax4.plot(end_j, end_i, 'wo', markersize=feat_markersz)\n",
    "    \n",
    "    ##subplot 5 - connection points\n",
    "    ax5 = plt.subplot(3,2,5)\n",
    "    ax5.set_title('Connections')\n",
    "    im5 = ax5.imshow(refl_img_prep.astype('float'))\n",
    "    #add skeleton\n",
    "    [line_i, line_j] = np.where(conn_skeleton)\n",
    "    ax5.plot(line_j, line_i, 'w.', markersize=ridge_markersz)\n",
    "    #overlay xsection\n",
    "    [line_i, line_j] = np.where(connect_point_mask)\n",
    "    ax5.plot(line_j, line_i, 'k.', markersize=feat_markersz)    \n",
    "    ax5.plot(end_j, end_i, 'wo', markersize=feat_markersz)\n",
    "        \n",
    "    ##subplot 6 - filter points\n",
    "    ax6 = plt.subplot(3,2,6)\n",
    "    ax6.set_title('Clean + Filter')\n",
    "    im6 = ax6.imshow(refl_img_prep.astype('float'))\n",
    "    #add skeleton\n",
    "    [line_i, line_j] = np.where(filter_skeleton)\n",
    "    ax6.plot(line_j, line_i, 'w.', markersize=ridge_markersz)\n",
    "\n",
    "    #ax0.set_title('Reflectivity')\n",
    "    #fig.colorbar(im0, ax=ax0)\n",
    "    #zoom if required\n",
    "    if zoom:\n",
    "        ax1.set_ylim(zoom_y)\n",
    "        ax1.set_xlim(zoom_x)\n",
    "        ax2.set_ylim(zoom_y)\n",
    "        ax2.set_xlim(zoom_x)\n",
    "        ax3.set_ylim(zoom_y)\n",
    "        ax3.set_xlim(zoom_x)\n",
    "        ax4.set_ylim(zoom_y)\n",
    "        ax4.set_xlim(zoom_x)\n",
    "        ax5.set_ylim(zoom_y)\n",
    "        ax5.set_xlim(zoom_x)\n",
    "        ax6.set_ylim(zoom_y)\n",
    "        ax6.set_xlim(zoom_x)\n",
    "        \n",
    "    #save\n",
    "    if save_flag:\n",
    "        image_ffn = output_path_full + '/' + str(image_index).zfill(3) + '.png'\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(image_ffn, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def production(image_index):\n",
    "    \n",
    "    #convert image to ridges\n",
    "    if original_lbdt_flag == True:\n",
    "        ridges_mask_inital, refl_img_prep, refl_img_crop = find_ridges_old(image_index)\n",
    "    else:\n",
    "        ridges_mask_inital, refl_img_prep, refl_img_crop = find_ridges_new(image_index)\n",
    "    #convert ridges to skeleton\n",
    "    skeleton, ridges_mask_filt = ridges_to_skeleton(ridges_mask_inital)\n",
    "    #remove intersections from skeleton\n",
    "    initial_skeleton = skeleton.copy()\n",
    "    skeleton, xsec_point_mask = remove_intersections(skeleton)\n",
    "    xsec_skeleton = skeleton.copy()\n",
    "    #remove turning points from keleton\n",
    "    skeleton, turn_point_mask = remove_turning_points(skeleton)\n",
    "    turn_skeleton = skeleton.copy()\n",
    "    #find end points and angles of end point\n",
    "    skeleton, end_point_mask, end_point_theta = find_end_points_and_theta(skeleton)\n",
    "    end_point_skeleton = skeleton.copy()\n",
    "    #connect end points using end point angles and distances\n",
    "    skeleton, connect_point_mask = connect_end_points(skeleton, \n",
    "                                    end_point_mask, end_point_theta, refl_img_prep)\n",
    "    conn_skeleton = skeleton.copy()\n",
    "    #remove short lines from skeleton\n",
    "    #skeleton = remove_short_lines(skeleton)\n",
    "    clean_skeleton = skeleton.copy()\n",
    "    #remove reflectivity edges and radial noise\n",
    "    skeleton = filter_edges_radialnoise(skeleton, refl_img_prep)\n",
    "    filter_skeleton = skeleton.copy()\n",
    "    #generate thinlines\n",
    "    thinlines_mask = skeleton_to_thinlines(skeleton, ridges_mask_inital)\n",
    "    \n",
    "    #plot\n",
    "    if full_plot:\n",
    "        generate_plot_full(refl_img_prep, refl_img_crop,\n",
    "                            initial_skeleton,\n",
    "                            xsec_skeleton, xsec_point_mask,\n",
    "                            turn_skeleton, turn_point_mask, \n",
    "                            end_point_skeleton, end_point_mask, end_point_theta,\n",
    "                            conn_skeleton, connect_point_mask,\n",
    "                            clean_skeleton,\n",
    "                            filter_skeleton,\n",
    "                            image_index)        \n",
    "    else:\n",
    "        generate_plot_simple(refl_img_prep, refl_img_crop, thinlines_mask, initial_skeleton, xsec_point_mask,\n",
    "                  turn_point_mask, \n",
    "                  end_point_mask, end_point_theta, connect_point_mask, filter_skeleton, image_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths\n",
    "input_ffn   = '/g/data/kl02/jss548/bonn-project-data/radolan_data/radolan_nc/RX-2013-08-06.nc'\n",
    "output_path_full = '/g/data/kl02/jss548/bonn-project-data/radolan_png_full'\n",
    "output_path_simple = '/g/data/kl02/jss548/bonn-project-data/radolan_png_simple'\n",
    "\n",
    "NCPU        = 15\n",
    "########################################################\n",
    "# read daily radolan NC file\n",
    "########################################################\n",
    "min_value    = -32.5 #dBZ\n",
    "grid_size_km = 1 #km\n",
    "\n",
    "########################################################\n",
    "# image to ridge mask to skeleton config\n",
    "########################################################\n",
    "#dimension limit in x\n",
    "x_start    = 145 #values in x dim less this this aren't present\n",
    "n_parm     = 3 #filter config\n",
    "min_length = 15. #min length for ridge regions (pixels)\n",
    "min_refl   = 0. #min/min reflectivity mask (dbz)\n",
    "max_refl   = 30.\n",
    "original_lbdt_flag = False\n",
    "########################################################\n",
    "# remove intersections config\n",
    "########################################################\n",
    "#LBP convolution windows\n",
    "n5_window = np.array([[1,1,1,1,1],\n",
    "                    [1,0,0,0,1],\n",
    "                    [1,0,0,0,1],\n",
    "                    [1,0,0,0,1],\n",
    "                    [1,1,1,1,1]])\n",
    "n3_window = np.array([[1,1,1],\n",
    "                    [1,0,1],\n",
    "                    [1,1,1]])\n",
    "\n",
    "\n",
    "########################################################\n",
    "# remove turning points config\n",
    "########################################################\n",
    "#number of points either size target point to calculate line segment vector from\n",
    "turnpt_vlen = 3 #pixels\n",
    "# minimum angle before a turning point is created\n",
    "turnpt_angle_threshold = 135 #deg\n",
    "\n",
    "########################################################\n",
    "# end point connecting config\n",
    "########################################################\n",
    "#number of points away from the end point to calculate the line segment angle for\n",
    "connect_calc_minpts = 3 #pixels\n",
    "#maximum distance for a connection\n",
    "connect_dist_max = 25 #pixel units\n",
    "#minimum reflectivity to cross for a connection\n",
    "min_line_refl    = -25 #dbz\n",
    "#maximum reflectivity to cross for a connection\n",
    "max_line_refl    = 40 #dbz\n",
    "#minimum angle for cosine similarity test\n",
    "cosine_test_val  = 135 #degrees\n",
    "\n",
    "########################################################\n",
    "# edge filter config\n",
    "########################################################\n",
    "# Th value for section 2.5.1 (Yuan et al. 2018)\n",
    "edge_filter_threshold = 0.75\n",
    "\n",
    "########################################################\n",
    "# plotting\n",
    "########################################################\n",
    "\n",
    "#marker sizes\n",
    "ridge_markersz = 1\n",
    "feat_markersz  = 2\n",
    "feat_markersz_connect = 2\n",
    "\n",
    "#zoom config\n",
    "zoom = True\n",
    "#larger zoom\n",
    "zoom_x = [400, 600]\n",
    "zoom_y = [100, 350]\n",
    "#norther subset\n",
    "# zoom_x = [500, 550]\n",
    "# zoom_y = [250, 300]\n",
    "#southern subset\n",
    "# zoom_x = [450, 525]\n",
    "# zoom_y = [100, 200]\n",
    "save_flag = False\n",
    "full_plot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read daily nc file\n",
    "with netCDF4.Dataset(input_ffn) as ncid:\n",
    "    refl_data = np.squeeze(ncid['rx'][:, :, :]).filled(min_value)\n",
    "    time_list = np.squeeze(ncid['time'][:])\n",
    "    time_units = ncid.variables['time'].units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production(208)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 75.0\n",
      "processed: 150.0\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "image_index_list = np.arange(0,len(time_list))[200:220]\n",
    "\n",
    "#multiprocessing\n",
    "chunked_list = util.chunks(image_index_list, NCPU)\n",
    "i            = 0\n",
    "n_items      = len(image_index_list)\n",
    "\n",
    "for one_slice in chunked_list:\n",
    "    with Pool(NCPU) as pool:\n",
    "        pool.map(production, one_slice)\n",
    "        #update user\n",
    "        i += NCPU\n",
    "        print('processed: ' + str(round(i/n_items*100, 2)))\n",
    "        \n",
    "print('Finished')\n",
    "\n",
    "# for image_index in image_index_list[206:207]:\n",
    "#     production(image_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: add radial filter\n",
    "look at tracking... need to use optical flow on convection then use the motion vectors to track boundaries?\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/205.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/206.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/207.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/208.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/209.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/210.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/211.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/212.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/213.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/214.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/215.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/216.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/217.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/218.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/219.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/220.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/221.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/222.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/223.png\n",
      "added /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/224.png\n",
      "finished /g/data/kl02/jss548/bonn-project-data/radolan_png_simple/movie2.gif\n"
     ]
    }
   ],
   "source": [
    "#lets make an animation!\n",
    "\n",
    "import imageio\n",
    "import glob\n",
    "\n",
    "out_path = output_path_simple\n",
    "\n",
    "movie_ffn = out_path + '/movie2.gif'\n",
    "filenames = sorted(glob.glob(out_path + '/*.png'))[10:30]\n",
    "\n",
    "with imageio.get_writer(movie_ffn, mode='I', fps=1) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "        print('added', filename)\n",
    "print('finished', movie_ffn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radar-vision",
   "language": "python",
   "name": "radar-vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
